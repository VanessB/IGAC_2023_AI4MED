{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05174999-1a8b-4dca-8403-e58528920dce",
   "metadata": {},
   "source": [
    "# Improved Baseline\n",
    "\n",
    "Улучшенное базовое решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63d6b6-ffc1-4420-b26d-15982c19ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71746ee-175b-424e-88b4-5c08cb027242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa875c25-adba-4a2f-8d0b-04b7379e6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data\")\n",
    "images_path = data_path / \"competition/competition/\"\n",
    "masks_path  = data_path / \"masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf1d33-5a1c-4f4b-8bdf-444c883f0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884a98f-2681-4638-9195-23db8cd73b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_improved_baseline_mask(image, min_treshold: float=0.17, max_treshold: float=0.4, verbose: int=0):\n",
    "    # Выделение внутренней части мозга.\n",
    "    brain_mask = get_brain_mask(image)\n",
    "    brain_area = np.sum(brain_mask)\n",
    "    \n",
    "    # Фильтрация изображения при помощи bilateralFilter.\n",
    "    image = np.minimum(image, brain_mask)\n",
    "    smoothed_image = cv2.bilateralFilter(image, 9, 0.1, 75)\n",
    "    brain_pixels = smoothed_image[brain_mask > 0.0]\n",
    "    \n",
    "    # Изначально выбираем top-1% пикселей.\n",
    "    start_treshold = max(0.17, min(0.24, np.percentile(brain_pixels, 99)))\n",
    "    _, mask = cv2.threshold(image, start_treshold, 1.0, cv2.THRESH_BINARY)\n",
    "    \n",
    "    max_steps = 100\n",
    "    for step in range(max_steps):\n",
    "        # Текущая площадь, занимаемая маской, в отношении к площади мозга.\n",
    "        area_to_brain_ratio = np.sum(mask) / brain_area\n",
    "        \n",
    "        # Вспомогательные параметры для выбора порога.\n",
    "        delta_percent   = 0.50 + 0.50 * np.exp(-step / 1.0) # Сколько процентов пикселей планируется добрать к маске.\n",
    "        percentile_mult = 0.99 - 0.01 * np.exp(-step / 2.0) # Во сколько раз дополнительно снизить порог.\n",
    "        lower_bound     = 0.15 + 0.03 * np.exp(-step / 2.0) # Нижнее ограничение на порог.\n",
    "        upper_bound     = 0.17 + 0.10 * np.exp(-step / 2.0) # Верхнее ограничение на порог.\n",
    "\n",
    "        # Выбор порога.\n",
    "        current_percent = 100.0 * (1.0 - area_to_brain_ratio)\n",
    "        new_percentile  = percentile_mult * np.percentile(brain_pixels, current_percent - delta_percent)\n",
    "        spread_treshold = min(upper_bound, max(lower_bound, new_percentile))\n",
    "        \n",
    "        if verbose >= 1:\n",
    "            # Информация о новом пороге и площади маски.\n",
    "            print(f\"{step}: th: {spread_treshold:.4f}, ma/ba: {area_to_brain_ratio:.3f}\")\n",
    "            \n",
    "            if verbose >= 2:\n",
    "                # Отрисовка самой маски.\n",
    "                plot_with_mask(smoothed_image, mask)\n",
    "            \n",
    "        # Выбор пикселей, соответствующих новому порогу.\n",
    "        _, mask_min = cv2.threshold(image, spread_treshold, 1.0, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Расширение текущей маски.\n",
    "        dilate_on_step_size = 15\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_on_step_size, dilate_on_step_size))\n",
    "        new_mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        \n",
    "        # Выбор пикселей, соответствующих новому порогу, и отстоящих на заданное расстояние от текущей маски.\n",
    "        new_mask = np.minimum(mask_min, new_mask)\n",
    "        \n",
    "        # Сглаживающие морфологические преобразования.\n",
    "        kernel_size = int(3.0 * np.exp(-step / 1.0))\n",
    "        if kernel_size:\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "            new_mask = cv2.morphologyEx(new_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        kernel_size = max(2, int(10.0 * np.exp(-step / 5.0)))\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "        new_mask = cv2.morphologyEx(new_mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Если маска почти не меняется, прекращаем работу.\n",
    "        if np.sum(np.abs(new_mask - mask)) <= 1e-6 * np.sum(mask):\n",
    "            mask = new_mask\n",
    "            break\n",
    "        \n",
    "        mask = new_mask\n",
    "        \n",
    "        # Постепенно убираем эффект фильтра исходного изображения.\n",
    "        beta = 0.1\n",
    "        smoothed_image = (1.0 - beta) * smoothed_image + beta * image\n",
    "        brain_pixels = smoothed_image[brain_mask > 0.0]\n",
    "        \n",
    "    if area_to_brain_ratio > 0.2 or area_to_brain_ratio < 0.002:\n",
    "        return get_baseline_mask(image)\n",
    "    \n",
    "    # Удаление мелких деталей.\n",
    "    #kernel_size = 3\n",
    "    #kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    #mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "    kernel_size = 5\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa5d3b-dbbd-4323-acdf-e589fb5df97d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in range(26600, 26725):\n",
    "    print(index)\n",
    "    name = f\"{index:06d}.jpg\"\n",
    "    image_path = images_path / name\n",
    "    \n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    baseline_mask = np.minimum(get_brain_mask(image), get_baseline_mask(image)).astype(bool)\n",
    "    mask = get_improved_baseline_mask(image, verbose=1)\n",
    "    #plot_with_mask(image, mask)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(2*8, 8))\n",
    "    \n",
    "    axes[0].imshow(np.maximum(image, baseline_mask))\n",
    "    axes[1].imshow(np.maximum(image, mask))\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6afd4-1abd-43c5-9497-d548446deadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = []\n",
    "\n",
    "for index in range(5):\n",
    "    name = f\"{index:06d}.jpg\"\n",
    "    image_path = images_path / name\n",
    "    mask_path  = masks_path  / name\n",
    "    \n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    true_mask = cv2.imread(str(mask_path))\n",
    "    true_mask = cv2.cvtColor(true_mask, cv2.COLOR_BGR2GRAY)\n",
    "    true_mask = cv2.normalize(true_mask, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    _, true_mask = cv2.threshold(true_mask, 0.5, 1.0, cv2.THRESH_BINARY)\n",
    "    \n",
    "    mask = get_improved_baseline_mask(image, verbose=1)\n",
    "    #mask = np.minimum(get_brain_mask(image), get_baseline_mask(image))\n",
    "    \n",
    "    plot_with_mask(image, mask)\n",
    "    \n",
    "    intersection_over_union = np.count_nonzero(np.minimum(mask, true_mask)) / np.count_nonzero(np.maximum(mask, true_mask))\n",
    "    #print(intersection_over_union)\n",
    "    ious.append(intersection_over_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4554102-0fa5-4326-82d0-01c66f684969",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ious) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba671a-f031-4f14-9aea-9118d97cf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_mask(name, mask):\n",
    "    numbers = pd.Series(np.arange(mask.size), name = 'ID')\n",
    "    ind = numbers.apply(lambda n: name + f\"_{n // mask.shape[1]}_{n % mask.shape[1]}\")\n",
    "    return pd.DataFrame({'value': mask.flatten()}, index = ind, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12889e2a-6e03-452d-a0d2-14fbf6898fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for index in tqdm(range(26600, 26725)):\n",
    "    name = f\"{index:06d}\"\n",
    "    image_path = images_path / (name + \".jpg\")\n",
    "    \n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    mask = get_improved_baseline_mask(image)\n",
    "    #mask = np.minimum(get_brain_mask(image), get_baseline_mask(image)).astype(bool)\n",
    "    \n",
    "    #answer = pd.concat([answer, df_from_mask(name, mask)])\n",
    "    dataframes.append(df_from_mask(name, mask))\n",
    "    \n",
    "    #fig = plt.figure(figsize=(10, 10))\n",
    "    #plt.imshow(mask)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d418385-f8a1-403a-9e16-e845a1ae0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.concat(dataframes)\n",
    "answer.to_csv('improved_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ddcf0-cdbe-4c55-b165-db6452597047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global AI",
   "language": "python",
   "name": "global_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
